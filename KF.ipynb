{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Imports:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\underline{\\text{Background material:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### $\\underline{\\text{Introduction to Kalman Filters:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __Kalman Filter__ is an optimal estimation algorithm used in general in control systems, robotics, and time-series forecasting. It estimates the hidden state of a dynamic system from noisy sensor measurement. \n",
    "\n",
    "The main assumption are that both the system and observation models are linear and that noise is Gaussian. \n",
    "\n",
    "The __Kalman Filter__ procedure is based into two steps:\n",
    "> - __Prediction__ : Estimates the next state based on the current state and control inputs. \n",
    "> - __Update__ : Adjusts the prediction based on the new measurement, thereby connectiing the estimate to account for measurement noise. \n",
    "\n",
    "Such a procedure is iteratively applied, updating the estimate as new observations become available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __Key properties of the Kalman Filter__ are then:\n",
    "> - __Gaussian Noise and Optimality__ : The Kalman filter is optimal / well specified when the noise is Gaussian. Indeed, the updating and prediction rules are based on Gaussian projection identites. \n",
    "> - __Real-time__: The filter updates online the state when it recieves a new observation, making it suitable for real-time applications. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\underline{\\text{Linear state space model for control systems:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a __linear state-space system__ model given by \n",
    "\n",
    "$$\n",
    "x_{k+1} = Ax_k + Bu_k + \\omega_k \\\\\n",
    "y_k = C x_k + D_k u_k + v_k\n",
    "$$\n",
    "\n",
    "where:\n",
    "> - $x_k \\in \\mathbb{R}^{2M^2}$ is the state vector at time step $k$.\n",
    "> - $u_k \\in \\mathbb{R}^{M}$ is the control vector input at time step $k$.\n",
    "> - $y_k \\in \\mathbb{R}^{M}$ is the observation vector at time step $k$.\n",
    "> - $A_k \\in \\mathbb{M}_{2M^{2}}(\\mathbb{R})$ is the state transition matrix. It can be seen as endogenous dynamics of the states. \n",
    "> - $B_k \\in \\mathbb{M}_{2M^{2},M}(\\mathbb{R})$ is the control matrix. It can be seen as the influence of the control (enxogenous character) on the state. \n",
    "> - $C_k \\in \\mathbb{M}_{M,2M^{2}}(\\mathbb{R})$ is the observation matrix, and coupled the state and control influence on the obsevrable.\n",
    "> - $D_k \\in \\mathbb{M}_{M,M}(\\mathbb{R})$ is the direct influence of the control on the observation. It is a purely exogenous perturbation to the system. \n",
    "> - $w_k$ and $v_k$ are assumed to be Gaussian noises. \n",
    "\n",
    "In particular we assume the following: \n",
    "\n",
    "> - __Process noise__: $w_k \\sim \\mathcal{N}(0,Q)$.\n",
    "> - __Observation noise__: $v_k \\sim \\mathcal{N}(0,R)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\underline{\\text{Maximum Likelihood Estimation for (static) Parameter Estimation:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the __KF__ implementation $A,B,C$ are unknown a priori (we can put a prior). We estimate these matrices from observed data using __Maximum Likelihood Estimation__ __(MLE)__.\n",
    "\n",
    "The model's log-likelihood is gicen by the __Gaussian__ assumption on the noise processes. \n",
    "\n",
    "The __MLE__ procedure consists in using the __KF__ iterations and compute the total log-likelihood generated. Then use _scipy_ to get the __MLE__ static parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\underline{\\text{The Kalman Filter class:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into the code implementation we present the __KalmanFilterWithMLE__ class. It has two functionalities, _fit the static parameter_ and _filter the state_ using the static parameters obtained from the __MLE__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterWithMLE:\n",
    "    def __init__(self, M, Q, R):\n",
    "        \"\"\"\n",
    "        Initializes the Kalman Filter with dimensions and noise covariances.\n",
    "\n",
    "        Parameters:\n",
    "        - M: Dimension parameter for control and observation vectors.\n",
    "        - Q: Process noise covariance matrix (shape: (2*M^2, 2*M^2)).\n",
    "        - R: Measurement noise covariance matrix (shape: (M, M)).\n",
    "        \"\"\"\n",
    "        # Model dimensions\n",
    "        self.M = M\n",
    "        self.state_dim = 2 * M**2  # Dimension of the state vector x\n",
    "        self.control_dim = M       # Dimension of the control vector u\n",
    "        self.obs_dim = M           # Dimension of the observation vector y\n",
    "\n",
    "        # Initial state and covariance\n",
    "        self.x = np.zeros(self.state_dim)\n",
    "        self.P = np.eye(self.state_dim)\n",
    "        self.Q = Q                 # Process noise covariance\n",
    "        self.R = R                 # Measurement noise covariance\n",
    "\n",
    "        # Initialize matrices A, B, C with random values for MLE estimation\n",
    "        self.A = np.random.randn(self.state_dim, self.state_dim)\n",
    "        self.B = np.random.randn(self.state_dim, self.control_dim)\n",
    "        self.C = np.random.randn(self.obs_dim, self.state_dim)\n",
    "\n",
    "    def reset(self, initial_state=None, initial_covariance=None):\n",
    "        \"\"\"\n",
    "        Resets the filter's state and covariance to specified initial values.\n",
    "\n",
    "        Parameters:\n",
    "        - initial_state: Optional, initial state vector (default: zero vector).\n",
    "        - initial_covariance: Optional, initial state covariance matrix (default: identity matrix).\n",
    "        \"\"\"\n",
    "        self.x = initial_state if initial_state is not None else np.zeros(self.state_dim)\n",
    "        self.P = initial_covariance if initial_covariance is not None else np.eye(self.state_dim)\n",
    "\n",
    "    def predict(self, u_k):\n",
    "        \"\"\"\n",
    "        Predicts the next state and covariance based on the current state and control input.\n",
    "\n",
    "        Parameters:\n",
    "        - u_k: Current control input (shape: (control_dim,))\n",
    "\n",
    "        Returns:\n",
    "        - x_pred: Predicted state (shape: (state_dim,))\n",
    "        - P_pred: Predicted covariance (shape: (state_dim, state_dim))\n",
    "        \"\"\"\n",
    "        x_pred = self.A @ self.x + self.B @ u_k\n",
    "        P_pred = self.A @ self.P @ self.A.T + self.Q\n",
    "        return x_pred, P_pred\n",
    "\n",
    "    def update(self, y_k, x_pred, P_pred):\n",
    "        \"\"\"\n",
    "        Updates the state and covariance based on the observation.\n",
    "\n",
    "        Parameters:\n",
    "        - y_k: Observation at the current time step (shape: (obs_dim,))\n",
    "        - x_pred: Predicted state from the predict step (shape: (state_dim,))\n",
    "        - P_pred: Predicted covariance from the predict step (shape: (state_dim, state_dim))\n",
    "\n",
    "        Returns:\n",
    "        - x_updated: Updated (filtered) state vector after incorporating observation.\n",
    "        \"\"\"\n",
    "        # Observation prediction\n",
    "        y_pred = self.C @ x_pred\n",
    "        # Innovation covariance\n",
    "        S = self.C @ P_pred @ self.C.T + self.R\n",
    "        # Kalman gain\n",
    "        K = P_pred @ self.C.T @ np.linalg.inv(S)\n",
    "\n",
    "        # State update with Kalman gain\n",
    "        self.x = x_pred + K @ (y_k - y_pred)\n",
    "        self.P = (np.eye(self.state_dim) - K @ self.C) @ P_pred\n",
    "        return self.x\n",
    "\n",
    "    def log_likelihood(self, params, Y, U):\n",
    "        \"\"\"\n",
    "        Computes the negative log-likelihood of the observed data given the parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - params: Flattened array of parameters A, B, C for optimization.\n",
    "        - Y: Sequence of observations (shape: (obs_dim, time_steps))\n",
    "        - U: Sequence of control inputs (shape: (control_dim, time_steps))\n",
    "\n",
    "        Returns:\n",
    "        - Negative log-likelihood of the observations given the parameters.\n",
    "        \"\"\"\n",
    "        # Unpack parameters from flat array\n",
    "        A = params[:self.state_dim**2].reshape(self.state_dim, self.state_dim)\n",
    "        B = params[self.state_dim**2:self.state_dim**2 + self.state_dim * self.control_dim].reshape(self.state_dim, self.control_dim)\n",
    "        C = params[self.state_dim**2 + self.state_dim * self.control_dim:].reshape(self.obs_dim, self.state_dim)\n",
    "        \n",
    "        # Initialize/reset state and covariance\n",
    "        self.reset()\n",
    "\n",
    "        log_likelihood = 0.0\n",
    "        # Iterate over the time steps\n",
    "        for t in range(Y.shape[1]):\n",
    "            y_k = Y[:, t]\n",
    "            u_k = U[:, t]\n",
    "            \n",
    "            # Predict step\n",
    "            x_pred, P_pred = self._predict_step(A, B, u_k)\n",
    "            # Calculate observation residual\n",
    "            y_pred = C @ x_pred\n",
    "            residual = y_k - y_pred\n",
    "            # Innovation covariance\n",
    "            S = C @ P_pred @ C.T + self.R\n",
    "            # Log-likelihood contribution for this step\n",
    "            log_likelihood += -0.5 * (residual.T @ np.linalg.inv(S) @ residual + np.log(np.linalg.det(S)))\n",
    "            \n",
    "            # Update step\n",
    "            self._update_step(C, residual, x_pred, P_pred, S)\n",
    "\n",
    "        return -log_likelihood\n",
    "\n",
    "    def fit(self, Y, U):\n",
    "        \"\"\"\n",
    "        Fits the parameters A, B, and C by maximizing the likelihood of the observed data.\n",
    "\n",
    "        Parameters:\n",
    "        - Y: Observed data sequence (shape: (obs_dim, time_steps))\n",
    "        - U: Control input sequence (shape: (control_dim, time_steps))\n",
    "\n",
    "        Returns:\n",
    "        - Optimized matrices A, B, C after fitting.\n",
    "        \"\"\"\n",
    "        # Initial parameter vector as a flattened array of A, B, C\n",
    "        initial_params = np.hstack([self.A.ravel(), self.B.ravel(), self.C.ravel()])\n",
    "        \n",
    "        # Minimize the negative log-likelihood using scipy's minimize function\n",
    "        result = minimize(self.log_likelihood, initial_params, args=(Y, U), method='L-BFGS-B')\n",
    "        \n",
    "        # Reshape optimized parameters back to matrices\n",
    "        opt_params = result.x\n",
    "        self.A = opt_params[:self.state_dim**2].reshape(self.state_dim, self.state_dim)\n",
    "        self.B = opt_params[self.state_dim**2:self.state_dim**2 + self.state_dim * self.control_dim].reshape(self.state_dim, self.control_dim)\n",
    "        self.C = opt_params[self.state_dim**2 + self.state_dim * self.control_dim:].reshape(self.obs_dim, self.state_dim)\n",
    "\n",
    "        return self.A, self.B, self.C\n",
    "\n",
    "    def filter_step(self, y_k, u_k):\n",
    "        \"\"\"\n",
    "        Executes a single filtering step with the current observation and control input.\n",
    "\n",
    "        Parameters:\n",
    "        - y_k: Current observation (shape: (obs_dim,))\n",
    "        - u_k: Current control input (shape: (control_dim,))\n",
    "\n",
    "        Returns:\n",
    "        - x_filtered: Updated state estimate.\n",
    "        - state_residual: Residual (difference between filtered and predicted state).\n",
    "        \"\"\"\n",
    "        # Predict state and covariance\n",
    "        x_pred, P_pred = self.predict(u_k)\n",
    "        \n",
    "        # Update state based on current observation\n",
    "        x_filtered = self.update(y_k, x_pred, P_pred)\n",
    "        \n",
    "        # Compute residual (difference between filtered and predicted state)\n",
    "        state_residual = x_filtered - x_pred\n",
    "        \n",
    "        return x_filtered, state_residual\n",
    "    \n",
    "    def _predict_step(self, A, B, u_k):\n",
    "        \"\"\"Helper function for internal predict step during likelihood calculation.\"\"\"\n",
    "        x_pred = A @ self.x + B @ u_k\n",
    "        P_pred = A @ self.P @ A.T + self.Q\n",
    "        return x_pred, P_pred\n",
    "\n",
    "    def _update_step(self, C, residual, x_pred, P_pred, S):\n",
    "        \"\"\"Helper function for internal update step during likelihood calculation.\"\"\"\n",
    "        K = P_pred @ C.T @ np.linalg.inv(S)\n",
    "        self.x = x_pred + K @ residual\n",
    "        self.P = (np.eye(self.state_dim) - K @ C) @ P_pred\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
